# Identifying Bad Data
Models are only as good as the datasets they are trained on. Some datasets contain better data than other datasets, and it's up to the researcher to identify which are good or bad datasets. As data scientists, we should be able to examine the dataset and identify whether the model is truly doing what it is stated to be doing. The datasets I use as examples are found in the Kaggle links within the writeup.

Some of the code was taken from a group project I participated in as part of my master's degree. I have labeled which code chunks that is not my original code and that I've adapted for this demonstration.

Language: Python<br>
Python Libraries: Numpy, Pandas, landsatxplore, , MatPlotLib, Pillow, foium, cv2, Sci-kit Learn, tensorflow, pickle, json, tifffile<br>
Statistics: Neural Networks

## Files
* Identifying_bad_datasets.ipynb: contains the writeup, analysis, code, and graphs for the project. To view all outputs and interact with the interactive maps, click the "Open in Colab" button to be redirected to Google Colab.
* identifying_bad_datasets_supplementary.ipynb: contains the code to generate the "urban" column for one of the datasets in the writeup.
* Canada_oecd_methodology.pdf: a pdf explaining how the functional urban areas of Canada were defined by the OECD.
* Canada_Wildfires_gov_website.jpg: screenshot of the Canada Wildfires government website to show the language used.
* Canada_Wildfires_kaggle.jpg: screenshot of the Canada Wildfires Kaggle page to show the language used.